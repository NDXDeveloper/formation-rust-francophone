# 7\. Le Multi-threading

üîù Retour √† la [Table des mati√®res](/SOMMAIRE.md)

## Introduction au multi-threading en Rust

Le multi-threading est un concept fondamental en programmation moderne, permettant d'ex√©cuter plusieurs segments de code en parall√®le. Rust offre une approche unique gr√¢ce √† son syst√®me de propri√©t√©, garantissant la s√©curit√© des donn√©es partag√©es entre threads.

Commen√ßons par un exemple simple :

``` rust
use std::thread;

fn main() {
    // On lance le thread
    let handle = thread::spawn(|| {
        println!("Salutations depuis un thread !");
        // On peut effectuer des op√©rations longues ici
        for i in 1..5 {
            println!("Compteur dans le thread: {}", i);
            // Simulons un traitement
            std::thread::sleep(std::time::Duration::from_millis(500));
        }
        // Valeur de retour du thread
        "Op√©ration termin√©e avec succ√®s"
    });

    println!("Le thread principal continue son ex√©cution pendant que le thread secondaire travaille");

    // On attend que le thread termine son travail avant de quitter
    let result = handle.join().unwrap();
    println!("Message du thread: {}", result);
}
```

La fonction `thread::spawn` ex√©cute le code de la closure dans un nouveau thread et renvoie un `JoinHandle`. Nous appelons ensuite la m√©thode `join()` pour attendre la fin de l'ex√©cution du thread et r√©cup√©rer sa valeur de retour.

## Partage de donn√©es entre threads

L'avantage de Rust r√©side dans sa gestion s√©curis√©e du partage de donn√©es. Essayons de partager des variables entre threads :

``` rust
use std::thread;

fn main() {
    let data = vec![1u32, 2, 3];

    // Tentative de capture directe
    let handle = thread::spawn(|| {
        // Ceci ne compilera pas
        println!("Les donn√©es dans le thread: {:?}", data);
    });

    handle.join().unwrap();
}
```

Ce code g√©n√®re une erreur de compilation car Rust ne peut pas garantir que la variable `data` restera valide pendant toute la dur√©e d'ex√©cution du thread. Nous pouvons utiliser le mot-cl√© `move` pour transf√©rer la propri√©t√© :

``` rust
use std::thread;

fn main() {
    let data = vec![1u32, 2, 3];

    // On transf√®re la propri√©t√© avec 'move'
    let handle = thread::spawn(move || {
        println!("Les donn√©es dans le thread: {:?}", data);
    });

    // Apr√®s move, data n'est plus accessible ici
    // println!("{:?}", data); // Erreur de compilation

    handle.join().unwrap();
}
```

Mais cela pose un autre probl√®me : que faire si nous voulons modifier les donn√©es dans plusieurs threads ? Essayons :

``` rust
use std::thread;

fn main() {
    let mut data = vec![1u32, 2, 3];
    let mut handles = Vec::new();

    for i in 0..3 {
        // On va tenter de modifier data dans chaque thread
        handles.push(thread::spawn(move || {
            data[i] += 1; // Erreur: plusieurs r√©f√©rences mutables
        }));
    }

    for handle in handles {
        handle.join().expect("√âchec de join");
    }
}
```

Ce code ne compilera pas car il viole les r√®gles fondamentales du syst√®me de propri√©t√© de Rust : nous essayons d'avoir plusieurs r√©f√©rences mutables √† `data` simultan√©ment.

## Solutions pour le partage s√©curis√©

Pour r√©soudre ce probl√®me, Rust propose plusieurs m√©canismes de synchronisation.

### Mutex (Mutual Exclusion)

Le `Mutex` permet d'utiliser une m√™me donn√©e depuis plusieurs endroits en garantissant qu'un seul thread y acc√®de √† la fois :

``` rust
use std::thread;
use std::sync::Mutex;

fn main() {
    // On cr√©e notre mutex contenant les donn√©es
    let data = Mutex::new(vec![1u32, 2, 3]);
    let mut handles = Vec::new();

    for i in 0..3 {
        // Ceci ne fonctionnera pas directement
        let data_clone = data.clone(); // Erreur : Mutex n'impl√©mente pas Clone

        handles.push(thread::spawn(move || {
            // On verrouille le mutex pour acc√©der aux donn√©es
            let mut locked_data = data_clone.lock().unwrap();
            locked_data[i] += 1;
        }));
    }

    for handle in handles {
        handle.join().expect("√âchec de join");
    }
}
```

Ce code ne compile pas car `Mutex` seul ne peut pas √™tre partag√© entre threads. C'est l√† qu'intervient `Arc`.

### Arc (Atomic Reference Counting)

`Arc` est similaire √† `Rc`, mais thread-safe gr√¢ce √† l'utilisation de compteurs atomiques et l'impl√©mentation du trait `Sync` :

``` rust
use std::sync::{Arc, Mutex};
use std::thread;

fn main() {
    // On combine Arc et Mutex pour un partage s√©curis√©
    let data = Arc::new(Mutex::new(vec![1u32, 2, 3]));
    let mut handles = Vec::new();

    for i in 0..3 {
        // On clone Arc (pas les donn√©es sous-jacentes)
        let data_clone = Arc::clone(&data);

        handles.push(thread::spawn(move || {
            // On verrouille pour modification
            let mut locked_data = data_clone.lock().unwrap();
            locked_data[i] += 1;
            println!("Thread {} a modifi√© la valeur √† {}", i, locked_data[i]);
        }));
    }

    for handle in handles {
        handle.join().expect("√âchec de join");
    }

    // V√©rification du r√©sultat final
    let result = data.lock().unwrap();
    println!("√âtat final des donn√©es: {:?}", *result);
}
```

Dans cet exemple, `Arc` permet de partager le `Mutex` entre threads, et le `Mutex` assure que seul un thread √† la fois peut modifier les donn√©es.

## Les Channels

Une autre approche pour la communication entre threads est l'utilisation de channels. Plut√¥t que de partager l'√©tat, on partage la communication :

```rust
use std::thread;
use std::sync::mpsc; // multiple producer, single consumer

fn main() {
    // Cr√©ation du channel
    let (tx, rx) = mpsc::channel();

    // Lancer des calculs dans des threads s√©par√©s
    for i in 1..5 {
        let tx_clone = tx.clone();
        thread::spawn(move || {
            // Simulation d'un calcul
            let result = i * i;
            println!("Thread {} a calcul√© {}", i, result);

            // Envoi du r√©sultat au thread principal
            tx_clone.send(result).expect("√âchec de l'envoi");
        });
    }

    // Lib√©rer le tx original (important!)
    drop(tx);

    // R√©ception et traitement des r√©sultats dans le thread principal
    let mut sum = 0;
    while let Ok(result) = rx.recv() {
        println!("Re√ßu: {}", result);
        sum += result;
    }

    println!("Somme de tous les r√©sultats: {}", sum);
}
```

Les channels sont particuli√®rement utiles pour impl√©menter des patterns de type "worker" o√π des t√¢ches sont distribu√©es √† plusieurs threads qui renvoient leurs r√©sultats au thread principal.

### Channels et timeout

Un probl√®me courant est d'√©viter que le thread principal attende ind√©finiment. Vous pouvez utiliser `recv_timeout` :

``` rust
use std::thread;
use std::sync::mpsc;
use std::time::Duration;

fn main() {
    let (tx, rx) = mpsc::channel();

    thread::spawn(move || {
        thread::sleep(Duration::from_secs(2));
        tx.send("R√©ponse tardive").unwrap();
    });

    match rx.recv_timeout(Duration::from_secs(1)) {
        Ok(msg) => println!("Re√ßu: {}", msg),
        Err(mpsc::RecvTimeoutError::Timeout) => println!("Timeout d√©pass√©, pas de r√©ponse dans le d√©lai imparti"),
        Err(mpsc::RecvTimeoutError::Disconnected) => println!("L'√©metteur a √©t√© d√©connect√©"),
    }
}
```

### Transmission synchrone avec `sync_channel`

Il existe √©galement une variante synchrone des channels qui limite la taille de la file d'attente :

``` rust
use std::thread;
use std::sync::mpsc;

fn main() {
    // Cr√©ation d'un channel synchrone avec une capacit√© de 2 messages
    let (tx, rx) = mpsc::sync_channel(2);

    thread::spawn(move || {
        for i in 1..6 {
            println!("Envoi de {}", i);
            // Bloquera apr√®s avoir envoy√© 2 messages jusqu'√† ce que le r√©cepteur consomme
            tx.send(i).unwrap();
            println!("Message {} envoy√©", i);
        }
    });

    thread::sleep(std::time::Duration::from_secs(1));

    for _ in 1..6 {
        let received = rx.recv().unwrap();
        println!("Re√ßu: {}", received);
        thread::sleep(std::time::Duration::from_millis(500));
    }
}
```

## Gestion des erreurs avec les threads

### Empoisonnement de Mutex

Un aspect important √† conna√Ætre est l'empoisonnement des Mutex. Si un thread panic! alors qu'il d√©tient le verrou d'un Mutex, celui-ci est marqu√© comme "empoisonn√©" :

``` rust
use std::sync::{Arc, Mutex};
use std::thread;

fn main() {
    let data = Arc::new(Mutex::new(0));
    let data_clone = Arc::clone(&data);

    // Un thread qui va paniquer
    let handle = thread::spawn(move || {
        let mut locked_data = data_clone.lock().unwrap();
        *locked_data += 1;

        // Simulons une erreur
        panic!("Oups, quelque chose s'est mal pass√©!");
    });

    // Le thread principal attend, mais le thread secondaire a paniqu√©
    let _ = handle.join();

    // Tentative d'acc√®s au mutex empoisonn√©
    match data.lock() {
        Ok(mut guard) => {
            *guard += 1;
            println!("Valeur actuelle: {}", *guard);
        },
        Err(poisoned) => {
            // On peut r√©cup√©rer les donn√©es malgr√© l'empoisonnement
            let mut guard = poisoned.into_inner();
            *guard += 1;
            println!("R√©cup√©r√© apr√®s empoisonnement: {}", *guard);
        }
    }
}
```

### Capturer les panics avec `join()`

Vous pouvez √©galement utiliser le r√©sultat de `join()` pour d√©tecter si un thread a paniqu√© :

``` rust
use std::thread;

fn main() {
    let handle = thread::spawn(|| {
        if rand::random::<bool>() {
            panic!("Simulation d'une erreur");
        } else {
            "Tout s'est bien pass√©"
        }
    });

    match handle.join() {
        Ok(result) => println!("Thread termin√© avec succ√®s: {}", result),
        Err(e) => println!("Thread paniqu√©: {:?}", e),
    }
}
```

## Les types atomiques

Les types atomiques permettent d'effectuer des op√©rations simples sur des valeurs partag√©es sans utiliser de verrous comme les Mutex :

``` rust
use std::sync::atomic::{AtomicU32, Ordering};
use std::sync::Arc;
use std::thread;

fn main() {
    let counter = Arc::new(AtomicU32::new(0));
    let mut handles = Vec::new();

    // Cr√©er 10 threads qui vont chacun incr√©menter le compteur 1000 fois
    for _ in 0..10 {
        let counter = Arc::clone(&counter);
        let handle = thread::spawn(move || {
            for _ in 0..1000 {
                // Incr√©menter de mani√®re atomique
                counter.fetch_add(1, Ordering::Relaxed);
            }
        });
        handles.push(handle);
    }

    // Attendre que tous les threads terminent
    for handle in handles {
        handle.join().unwrap();
    }

    println!("Compteur final: {}", counter.load(Ordering::Relaxed));
}
```

Les op√©rations atomiques sont plus efficaces que les Mutex pour des op√©rations simples comme les compteurs.

### Ordonnancement de la m√©moire

Le param√®tre `Ordering` d√©termine les garanties de synchronisation de m√©moire :

- `Relaxed` : aucune garantie synchronisation de m√©moire suppl√©mentaire, uniquement l'atomicit√© de l'op√©ration
- `Acquire` : pour les op√©rations de lecture (emp√™che la r√©organisation des lectures/√©critures suivantes)
- `Release` : pour les op√©rations d'√©criture (emp√™che la r√©organisation des lectures/√©critures pr√©c√©dentes)
- `AcqRel` : combine Acquire et Release (pour les op√©rations d'√©change)
- `SeqCst` : l'ordonnancement le plus strict, garantit un ordre total sur toutes les op√©rations

``` rust
use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::Arc;
use std::thread;
use std::sync::atomic::AtomicU32;

fn main() {
    let flag = Arc::new(AtomicBool::new(false));
    let data = Arc::new(AtomicU32::new(0));

    // Thread producteur
    let flag_clone = Arc::clone(&flag);
    let data_clone = Arc::clone(&data);
    let producer = thread::spawn(move || {
        // Effectuer des calculs
        data_clone.store(42, Ordering::Relaxed);
        // Signaler que les donn√©es sont pr√™tes (avec synchronisation)
        flag_clone.store(true, Ordering::Release);
    });

    // Thread consommateur
    let consumer = thread::spawn(move || {
        // Attendre que le flag soit activ√©
        while !flag.load(Ordering::Acquire) {
            thread::yield_now(); // C√©der le CPU
        }

        // √Ä ce stade, on est assur√© de voir la valeur 42 dans data
        let value = data.load(Ordering::Relaxed);
        assert_eq!(value, 42);
    });

    producer.join().unwrap();
    consumer.join().unwrap();
}
```

## Gestion de threads avanc√©e avec `crossbeam`

La biblioth√®que `crossbeam` offre des outils plus sophistiqu√©s pour la concurrence :

``` rust
use crossbeam_channel as channel;
use std::thread;
use std::time::Duration;

fn main() {
    // Canal sans capacit√© limite
    let (s, r) = channel::unbounded();

    // Envoyer des messages depuis plusieurs threads producteurs
    for i in 0..5 {
        let s = s.clone();
        thread::spawn(move || {
            s.send(format!("Message du producteur {}", i)).unwrap();
        });
    }

    // Cr√©er un deadlane apr√®s lequel on arr√™te d'attendre
    let timeout = Duration::from_secs(1);

    // Recevoir les messages pendant un certain temps
    while let Ok(msg) = channel::select! {
        recv(r) -> msg => {
            // Convertir le Result<String, RecvError> en Result<String, RecvTimeoutError>
            msg.map_err(|_| channel::RecvTimeoutError::Disconnected)
        },
        default(timeout) => Err(channel::RecvTimeoutError::Timeout),
    } {
        println!("Re√ßu: {}", msg);
    }

    println!("Temps √©coul√© ou tous les messages ont √©t√© re√ßus");
}
```

### Scoped threads avec `crossbeam`

Un probl√®me courant en Rust est de r√©f√©rencer des variables locales dans des threads. `crossbeam` propose des threads √† port√©e limit√©e qui sont automatiquement joints √† la fin de leur port√©e :

``` rust
use crossbeam::thread;

fn main() {
    let numbers = vec![1, 2, 3, 4, 5];
    let mut results = vec![0; 5];

    // Tous les threads cr√©√©s ici sont joints √† la fin du bloc
    thread::scope(|s| {
        for (i, &num) in numbers.iter().enumerate() {
            // On peut emprunter des r√©f√©rences aux variables locales
            s.spawn(move |_| {
                // Calcul co√ªteux
                let result = num * num;
                // On peut √©crire directement dans results
                results[i] = result;
            });
        }
        // Tous les threads sont automatiquement joints ici
    }).unwrap();

    println!("R√©sultats: {:?}", results);
}
```

## Pools de threads

Pour les applications n√©cessitant beaucoup de t√¢ches parall√®les, il est souvent plus efficace de r√©utiliser les threads plut√¥t que d'en cr√©er de nouveaux √† chaque fois. Voici un exemple simple utilisant `threadpool` :

``` rust
use threadpool::ThreadPool;
use std::sync::mpsc::channel;

fn main() {
    let n_workers = 4;
    let n_jobs = 8;
    let pool = ThreadPool::new(n_workers);

    let (tx, rx) = channel();

    // Soumettre des t√¢ches au pool
    for i in 0..n_jobs {
        let tx = tx.clone();
        pool.execute(move || {
            // Travail simul√©
            let result = i * i;
            tx.send(result).expect("√âchec de l'envoi du r√©sultat");
        });
    }

    drop(tx);

    // Collecter les r√©sultats
    let mut results = Vec::new();
    while let Ok(result) = rx.recv() {
        results.push(result);
    }

    // Attendre que toutes les t√¢ches soient termin√©es
    pool.join();

    // Trier pour un affichage pr√©visible
    results.sort();
    println!("R√©sultats: {:?}", results);
}
```

## Rayon : parall√©lisme de donn√©es

La biblioth√®que `rayon` simplifie consid√©rablement le parall√©lisme en Rust en proposant des it√©rateurs parall√®les :

``` rust
use rayon::prelude::*;

fn main() {
    let nombres = vec![1, 2, 3, 4, 5, 6, 7, 8, 9, 10];

    // Calcul s√©quentiel
    let somme_seq: u64 = nombres.iter()
                                .map(|&x| {
                                    // Simuler un calcul co√ªteux
                                    let y = x * x;
                                    y as u64
                                })
                                .sum();

    // Version parall√®le avec rayon
    let somme_par: u64 = nombres.par_iter()
                                .map(|&x| {
                                    // Le m√™me calcul, mais ex√©cut√© en parall√®le
                                    let y = x * x;
                                    y as u64
                                })
                                .sum();

    println!("Somme s√©quentielle: {}", somme_seq);
    println!("Somme parall√®le: {}", somme_par);

    // Division-fusion parall√®le avec rayon
    let resultat = nombres.par_iter()
                         .filter(|&&x| x % 2 == 0)  // Garder les nombres pairs
                         .map(|&x| x * x)           // √âlever au carr√©
                         .reduce(|| 0, |a, b| a + b); // R√©duire en somme

    println!("Somme des carr√©s des nombres pairs: {}", resultat);
}
```

## Conclusion

Le multi-threading en Rust combine s√©curit√© des types et performance gr√¢ce √† plusieurs m√©canismes :

1.  Le syst√®me de propri√©t√© emp√™che les conditions de course au moment de la compilation
2.  Les `Mutex` et `Arc` permettent le partage s√©curis√© de donn√©es mutables
3.  Les channels facilitent la communication entre threads
4.  Les types atomiques offrent des op√©rations l√©g√®res sans verrouillage
5.  Des biblioth√®ques comme `crossbeam` et `rayon` simplifient les patterns complexes

En suivant ces principes, vous pouvez d√©velopper des applications concurrentes robustes et performantes sans les bugs difficiles √† reproduire qui affligent habituellement la programmation parall√®le.

‚è≠Ô∏è [Le r√©seau](/III-avance/08-reseau.md)
