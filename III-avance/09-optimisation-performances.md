## 9\. Optimisation des performances - Profiling, benchmarking avec Criterion

üîù Retour √† la [Table des mati√®res](/SOMMAIRE.md)

### Introduction

L'optimisation des performances est une √©tape cruciale du d√©veloppement de logiciels performants en Rust. Cette section explore les techniques pour identifier les goulots d'√©tranglement dans vos programmes et mesurer pr√©cis√©ment les am√©liorations apport√©es par vos optimisations.

Rust est con√ßu pour offrir des performances proches du C/C++ tout en garantissant la s√©curit√© m√©moire. Mais comme pour tout langage, il est important de savoir o√π et comment optimiser.

### Principes d'optimisation

Avant de plonger dans les outils, gardons √† l'esprit quelques principes g√©n√©raux d'optimisation :

1.  **Mesurer avant d'optimiser** : Les intuitions sur la performance sont souvent trompeuses.
2.  **Identifier les points chauds** : Concentrez vos efforts sur les 20% du code qui consomment 80% du temps d'ex√©cution.
3.  **Comparer les alternatives** : Utilisez des benchmarks pour comparer plusieurs approches.
4.  **Maintenir la lisibilit√© du code** : Une optimisation qui rend le code incompr√©hensible est rarement justifi√©e.

### Profiling en Rust

Le profiling consiste √† analyser l'ex√©cution de votre programme pour identifier les parties consommant le plus de ressources.

#### Outils de profiling

Plusieurs outils sont disponibles pour le profiling de code Rust :

1.  **perf** (Linux) : Outil d'analyse de performance du noyau Linux
2.  **Instruments** (macOS) : Suite d'outils de profiling d'Apple
3.  **Valgrind** avec Callgrind/KCachegrind : Pour une analyse d√©taill√©e de l'utilisation CPU
4.  **flamegraph** : Visualisation hi√©rarchique du temps CPU
5.  **tracy** : Profiler graphique √† faible surcharge
6.  **pprof** : Visualisation de profils de performance

#### Exemple avec perf et flamegraph

Commen√ßons par installer les outils n√©cessaires :

``` bash
# Sur un syst√®me Debian/Ubuntu
sudo apt-get install linux-tools-common linux-tools-generic
cargo install flamegraph
```

Cr√©ons un programme Rust avec un point chaud √©vident :

``` rust
// src/main.rs
fn fonction_lente(n: u64) -> u64 {
    let mut somme = 0;
    for i in 0..n {
        somme += i;
        // Simulation de travail suppl√©mentaire
        for _ in 0..100 {
            somme = somme.wrapping_add(1).wrapping_sub(1);
        }
    }
    somme
}

fn fonction_rapide(n: u64) -> u64 {
    // Formule de Gauss: somme des n premiers entiers = n*(n+1)/2
    n * (n + 1) / 2
}

fn main() {
    let n = 50_000;

    // Mesure du temps pour la m√©thode lente
    let debut = std::time::Instant::now();
    let resultat1 = fonction_lente(n);
    let duree_lente = debut.elapsed();

    // Mesure du temps pour la m√©thode rapide
    let debut = std::time::Instant::now();
    let resultat2 = fonction_rapide(n);
    let duree_rapide = debut.elapsed();

    println!("M√©thode lente: {} en {:?}", resultat1, duree_lente);
    println!("M√©thode rapide: {} en {:?}", resultat2, duree_rapide);
    println!("Rapport de performance: {:.2}x",
        duree_lente.as_secs_f64() / duree_rapide.as_secs_f64());
}
```

Pour profiler ce programme avec flamegraph :

``` bash
cargo flamegraph
```

Cela g√©n√®re un fichier SVG visualisant la r√©partition du temps CPU dans notre application. Les sections les plus larges du graphique correspondent aux fonctions consommant le plus de CPU.

#### Analyse de l'allocation m√©moire

Pour analyser les allocations m√©moire, vous pouvez utiliser DHAT (via Valgrind) ou jemallocator avec le profiling activ√© :

``` rust
// Cargo.toml
[dependencies]
jemallocator = { version = "0.5", features = ["profiling"] }

// main.rs
#[global_allocator]
static ALLOC: jemallocator::Jemalloc = jemallocator::Jemalloc;

fn main() {
    // Votre code ici

    // √âcrire les statistiques d'allocation dans un fichier
    unsafe {
        jemallocator::stats::dump_stats("jeprof.out").unwrap();
    }
}
```

### Benchmarking avec Criterion

Criterion est une crate qui permet de r√©aliser des benchmarks pr√©cis et statistiquement significatifs. Contrairement au benchmarking int√©gr√© √† Rust (qui est encore instable), Criterion est stable et facile √† utiliser.

#### Configuration initiale

Commen√ßons par configurer Criterion dans notre projet :

``` toml
# Cargo.toml
[dev-dependencies]
criterion = "0.5"

[[bench]]
name = "mon_benchmark"
harness = false
```

Ensuite, cr√©ons un fichier de benchmark dans `benches/mon_benchmark.rs` :

``` rust
use criterion::{black_box, criterion_group, criterion_main, Criterion};

// Fonction √† benchmarker - Tri √† bulles
fn tri_bulles(mut liste: Vec<i32>) -> Vec<i32> {
    let n = liste.len();
    for i in 0..n {
        for j in 0..(n - i - 1) {
            if liste[j] > liste[j + 1] {
                liste.swap(j, j + 1);
            }
        }
    }
    liste
}

// Fonction √† comparer - Tri rapide
fn tri_rapide(mut liste: Vec<i32>) -> Vec<i32> {
    if liste.len() <= 1 {
        return liste;
    }

    let pivot = liste.remove(0);
    let mut plus_petits = Vec::new();
    let mut plus_grands = Vec::new();

    for x in liste {
        if x <= pivot {
            plus_petits.push(x);
        } else {
            plus_grands.push(x);
        }
    }

    let mut resultat = tri_rapide(plus_petits);
    resultat.push(pivot);
    resultat.extend(tri_rapide(plus_grands));
    resultat
}

fn benchmark_tris(c: &mut Criterion) {
    let mut groupe = c.benchmark_group("Algorithmes de tri");

    // G√©n√©ration de donn√©es al√©atoires
    let donnees: Vec<i32> = (0..1000).map(|_| rand::random::<i32>()).collect();

    // Benchmark du tri √† bulles
    groupe.bench_function("Tri √† bulles", |b| {
        b.iter(|| tri_bulles(black_box(donnees.clone())))
    });

    // Benchmark du tri rapide
    groupe.bench_function("Tri rapide", |b| {
        b.iter(|| tri_rapide(black_box(donnees.clone())))
    });

    groupe.finish();
}

criterion_group!(benches, benchmark_tris);
criterion_main!(benches);
```

Ajoutons la d√©pendance rand pour g√©n√©rer des nombres al√©atoires :

``` toml
[dev-dependencies]
criterion = "0.5"
rand = "0.8"
```

Pour ex√©cuter les benchmarks :

``` bash
cargo bench
```

#### Interpr√©tation des r√©sultats

Criterion g√©n√®re un rapport HTML d√©taill√© dans `target/criterion/` avec :

- Temps d'ex√©cution moyens
- √âcarts-types et intervalles de confiance
- Graphiques de comparaison
- D√©tection automatique de r√©gression de performance

#### Param√®tres avanc√©s de Criterion

Criterion offre de nombreuses options pour personnaliser vos benchmarks :

``` rust
fn benchmark_parametrique(c: &mut Criterion) {
    let mut groupe = c.benchmark_group("Taille variable");

    // Tester avec diff√©rentes tailles d'entr√©e
    for taille in [10, 100, 1000, 10000].iter() {
        groupe.bench_with_input(
            format!("Tri √† bulles {}", taille),
            taille,
            |b, &taille| {
                // G√©n√©ration des donn√©es avec la taille sp√©cifi√©e
                let donnees: Vec<i32> = (0..taille).map(|_| rand::random::<i32>()).collect();
                b.iter(|| tri_bulles(black_box(donnees.clone())))
            }
        );
    }

    groupe.finish();
}
```

### Micro-optimisations en Rust

Voyons quelques techniques d'optimisation sp√©cifiques √† Rust :

#### 1\. Choix des types appropri√©s

``` rust
fn benchmark_types(c: &mut Criterion) {
    let mut groupe = c.benchmark_group("Types");

    // Benchmark avec Vec<i32>
    groupe.bench_function("Vec<i32>", |b| {
        b.iter(|| {
            let mut v = Vec::new();
            for i in 0..1000 {
                v.push(i);
            }
            black_box(v)
        })
    });

    // Benchmark avec Vec<i32> pr√©allou√©
    groupe.bench_function("Vec<i32> pr√©allou√©", |b| {
        b.iter(|| {
            let mut v = Vec::with_capacity(1000);
            for i in 0..1000 {
                v.push(i);
            }
            black_box(v)
        })
    });

    // Benchmark avec [i32; 1000]
    groupe.bench_function("Array [i32; 1000]", |b| {
        b.iter(|| {
            let mut arr = [0i32; 1000];
            for i in 0..1000 {
                arr[i] = i;
            }
            black_box(arr)
        })
    });

    groupe.finish();
}
```

#### 2\. Optimisation des it√©rateurs

``` rust
fn somme_avec_for(v: &[i32]) -> i32 {
    let mut somme = 0;
    for x in v {
        somme += x;
    }
    somme
}

fn somme_avec_iter(v: &[i32]) -> i32 {
    v.iter().sum()
}

fn somme_avec_iter_fold(v: &[i32]) -> i32 {
    v.iter().fold(0, |acc, x| acc + x)
}

fn benchmark_iterations(c: &mut Criterion) {
    let donnees: Vec<i32> = (0..10000).collect();

    let mut groupe = c.benchmark_group("Techniques d'it√©ration");

    groupe.bench_function("For loop", |b| {
        b.iter(|| somme_avec_for(black_box(&donnees)))
    });

    groupe.bench_function("Iterator sum", |b| {
        b.iter(|| somme_avec_iter(black_box(&donnees)))
    });

    groupe.bench_function("Iterator fold", |b| {
        b.iter(|| somme_avec_iter_fold(black_box(&donnees)))
    });

    groupe.finish();
}
```

#### 3\. Caches et r√©utilisation des calculs

Prenons l'exemple d'un algorithme de calcul du nombre de Fibonacci :

``` rust
// Version na√Øve - calcul r√©cursif
fn fibonacci_naif(n: u64) -> u64 {
    match n {
        0 => 0,
        1 => 1,
        _ => fibonacci_naif(n - 1) + fibonacci_naif(n - 2),
    }
}

// Version optimis√©e - m√©mo√Øsation avec table de hachage
use std::collections::HashMap;

fn fibonacci_memo(n: u64, cache: &mut HashMap<u64, u64>) -> u64 {
    if let Some(&result) = cache.get(&n) {
        return result;
    }

    let result = match n {
        0 => 0,
        1 => 1,
        _ => fibonacci_memo(n - 1, cache) + fibonacci_memo(n - 2, cache),
    };

    cache.insert(n, result);
    result
}

// Version it√©rative - approche ascendante
fn fibonacci_iteratif(n: u64) -> u64 {
    if n <= 1 {
        return n;
    }

    let mut a = 0;
    let mut b = 1;

    for _ in 2..=n {
        let temp = a + b;
        a = b;
        b = temp;
    }

    b
}

fn benchmark_fibonacci(c: &mut Criterion) {
    let mut groupe = c.benchmark_group("Fibonacci");

    // On limite √† un petit n pour la version na√Øve qui est exponentielle
    groupe.bench_function("Na√Øf (n=20)", |b| {
        b.iter(|| fibonacci_naif(black_box(20)))
    });

    groupe.bench_function("M√©mo√Øsation (n=50)", |b| {
        b.iter(|| {
            let mut cache = HashMap::new();
            fibonacci_memo(black_box(50), &mut cache)
        })
    });

    groupe.bench_function("It√©ratif (n=50)", |b| {
        b.iter(|| fibonacci_iteratif(black_box(50)))
    });

    groupe.finish();
}
```

### Optimisation des fonctions hachage

Illustrons un cas pratique avec l'utilisation de diff√©rentes fonctions de hachage, en utilisant les crates mentionn√©es dans vos d√©pendances :

``` rust
use criterion::{black_box, criterion_group, criterion_main, Criterion};
use md5::Md5;
use sha1::Sha1;
use sha2::{Sha256, Sha512, Digest};

fn hash_md5(donnees: &[u8]) -> [u8; 16] {
    let mut hasher = Md5::new();
    hasher.update(donnees);
    hasher.finalize().into()
}

fn hash_sha1(donnees: &[u8]) -> [u8; 20] {
    let mut hasher = Sha1::new();
    hasher.update(donnees);
    hasher.finalize().into()
}

fn hash_sha256(donnees: &[u8]) -> [u8; 32] {
    let mut hasher = Sha256::new();
    hasher.update(donnees);
    hasher.finalize().into()
}

fn hash_sha512(donnees: &[u8]) -> [u8; 64] {
    let mut hasher = Sha512::new();
    hasher.update(donnees);
    hasher.finalize().into()
}

fn hash_crc32(donnees: &[u8]) -> u32 {
    crc::Crc::<u32>::new(&crc::CRC_32_ISO_HDLC).checksum(donnees)
}

fn benchmark_hash(c: &mut Criterion) {
    // G√©n√©rer une cha√Æne de 1KB pour le test
    let test_data = vec![0u8; 1024];

    let mut groupe = c.benchmark_group("Fonctions de hachage");

    groupe.bench_function("MD5", |b| {
        b.iter(|| hash_md5(black_box(&test_data)))
    });

    groupe.bench_function("SHA-1", |b| {
        b.iter(|| hash_sha1(black_box(&test_data)))
    });

    groupe.bench_function("SHA-256", |b| {
        b.iter(|| hash_sha256(black_box(&test_data)))
    });

    groupe.bench_function("SHA-512", |b| {
        b.iter(|| hash_sha512(black_box(&test_data)))
    });

    groupe.bench_function("CRC32", |b| {
        b.iter(|| hash_crc32(black_box(&test_data)))
    });

    groupe.finish();
}

criterion_group!(benches, benchmark_hash);
criterion_main!(benches);
```

### Optimisation des allocations m√©moire

Une source commune de probl√®mes de performance en Rust est l'allocation m√©moire excessive :

``` rust
fn benchmark_allocations(c: &mut Criterion) {
    let mut groupe = c.benchmark_group("Allocations");

    // Concat√©nation de cha√Ænes avec allocation √† chaque it√©ration
    groupe.bench_function("String += (inefficace)", |b| {
        b.iter(|| {
            let mut resultat = String::new();
            for i in 0..1000 {
                resultat += &i.to_string();
            }
            black_box(resultat)
        })
    });

    // Utilisation de String::with_capacity pour pr√©allouer
    groupe.bench_function("String::with_capacity", |b| {
        b.iter(|| {
            let mut resultat = String::with_capacity(4000); // Estimation approximative
            for i in 0..1000 {
                resultat += &i.to_string();
            }
            black_box(resultat)
        })
    });

    // Utilisation de String::push_str pour √©viter les allocations temporaires
    groupe.bench_function("push_str", |b| {
        b.iter(|| {
            let mut resultat = String::with_capacity(4000);
            for i in 0..1000 {
                resultat.push_str(&i.to_string());
            }
            black_box(resultat)
        })
    });

    // Utilisation d'un StringBuilder (format!)
    groupe.bench_function("format! macro", |b| {
        b.iter(|| {
            let mut morceaux = Vec::with_capacity(1000);
            for i in 0..1000 {
                morceaux.push(i.to_string());
            }
            let resultat = format!("{}", morceaux.join(""));
            black_box(resultat)
        })
    });

    groupe.finish();
}
```

### Optimisation multithread avec crossbeam-channel

La crate `crossbeam-channel` mentionn√©e dans vos d√©pendances est excellente pour parall√©liser les calculs. Voici un exemple de benchmark :

``` rust
use crossbeam_channel::{bounded, unbounded};
use std::thread;

fn traitement_sequentiel(donnees: &[i32]) -> Vec<i32> {
    donnees.iter().map(|x| x * x).collect()
}

fn traitement_parallele(donnees: &[i32], nb_threads: usize) -> Vec<i32> {
    let (sender, receiver) = unbounded();
    let (result_sender, result_receiver) = bounded(donnees.len());

    // Diviser les donn√©es en morceaux
    let taille_chunk = (donnees.len() + nb_threads - 1) / nb_threads;

    // Lancer les threads de travail
    for _ in 0..nb_threads {
        let sender_clone = sender.clone();
        let result_sender_clone = result_sender.clone();

        thread::spawn(move || {
            while let Ok((index, valeur)) = sender_clone.recv() {
                let resultat = valeur * valeur;
                result_sender_clone.send((index, resultat)).unwrap();
            }
        });
    }

    // Envoyer les donn√©es aux threads
    for (i, &valeur) in donnees.iter().enumerate() {
        sender.send((i, valeur)).unwrap();
    }

    // Fermer le canal pour indiquer qu'il n'y a plus de donn√©es
    drop(sender);
    drop(result_sender);

    // R√©cup√©rer les r√©sultats
    let mut resultats = vec![0; donnees.len()];
    while let Ok((index, resultat)) = result_receiver.recv() {
        resultats[index] = resultat;
    }

    resultats
}

fn benchmark_parallelisme(c: &mut Criterion) {
    // G√©n√©rer un grand tableau de donn√©es
    let donnees: Vec<i32> = (0..100_000).collect();

    let mut groupe = c.benchmark_group("Parall√©lisme");

    groupe.bench_function("S√©quentiel", |b| {
        b.iter(|| traitement_sequentiel(black_box(&donnees)))
    });

    let nb_threads = num_cpus::get();
    groupe.bench_function(format!("Parall√®le ({} threads)", nb_threads), |b| {
        b.iter(|| traitement_parallele(black_box(&donnees), nb_threads))
    });

    groupe.finish();
}
```

### Conseils pour l'optimisation

1.  **Compiler en mode release** : Les optimisations du compilateur font souvent une √©norme diff√©rence.

``` bash
cargo run --release
cargo bench  # Les benchmarks sont d√©j√† en mode release
```

2.  **Utiliser les optimisations √† la compilation** : Dans `Cargo.toml` :

``` toml
[profile.release]
opt-level = 3
lto = "fat"  # Link-Time Optimization
codegen-units = 1
panic = "abort"  # Simplifier le code de gestion des panics
```

3.  **Analyser les allocations** : Souvent, r√©duire les allocations am√©liore grandement les performances.

4.  **Parall√©liser intelligemment** : Utilisez `rayon` ou `crossbeam` pour les t√¢ches parall√©lisables.

5.  **Mesurer, optimiser, mesurer √† nouveau** : Ne supposez jamais qu'une modification am√©liore les performances sans le v√©rifier.


### Conclusion

L'optimisation des performances en Rust n√©cessite une compr√©hension des outils de profiling et de benchmarking, ainsi que des sp√©cificit√©s du langage. Criterion offre un moyen robuste de mesurer les performances et de comparer diff√©rentes approches.

N'oubliez pas que Rust est d√©j√† optimis√© par d√©faut gr√¢ce √† son mod√®le d'ownership, son absence de garbage collector et ses abstractions √† co√ªt z√©ro. Souvent, l'optimisation la plus efficace consiste simplement √† utiliser les bonnes abstractions que le langage et son √©cosyst√®me offrent d√©j√†.

Comme le dit Donald Knuth : "L'optimisation pr√©matur√©e est la racine de tous les maux". Concentrez-vous d'abord sur l'exactitude et la clart√© du code, puis optimisez les parties critiques identifi√©es par le profiling.

‚è≠Ô∏è [Rust embarqu√©](/III-avance/10-rust-embarque.md) - Introduction √† la programmation sur microcontr√¥leurs
